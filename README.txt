Created by Sydney Blattman, modernized by Jakob Peder Pettersen
Last updated: 28/11/2025

Dependencies:
python 3.12.12
fastqc (v0.12.1)
cutadapt (v5.2)
seqkit v2.11.0
GNU parallel (20251122)
UMI-tools (v1.1.6)
subread (v2.1.1, contains featureCounts)
bwa (0.7.19)
samtools 1.7
PEAR (0.9.6) [note we have only been able to install PEAR on linux not mac]
pandas (2.3.3)
matplotlib (3.10.8)
numpy (2.3.5)

Pipeline:
Example commands can be run from demo folder
1. Create a folder with the sample name (eg random20000, which is already in demo folder) and put fastq.gz files in this folder (all lanes, paired end)
Run the following from directory containing the folder with sample name 
2. Make sure all fastq files have names in the form: {sample name}_{S#}_L00{#}_R1_001.fastq.gz or {sample name}_{S#}_L00{#}_R2_001.fastq.gz
	For example, the file names for demo sample lane 1 would be: random20000_S1_L001_R1_001.fastq.gz and random20000_S1_L001_R2_001.fastq.gz
3. SCRIPT: ./commands.sh [full path to scripts folder] # from demo folder
	# first line is: python [path to scripts folder]/sc_pipeline_15_generic.py {full_sample} {n_lanes} 
		# full_sample is sample name and S number (eg random20000_S1)
		# n_lanes is the number of sequencing lanes for analysis - if lanes are merged, then the single file should be names with suffix _L001_R1_001.fastq.gz and n_lanes set to 1. The script will count lanes from 1 to n_lanes so always start numbering from 1.
		# sc_pipeline_15_generic.py runs fastqc, quality filter, and barcode demultiplexing
		# This step will take a few hours for ~50 million reads
	# second line is: [path to scripts folder]/pipeline_v2.sh {sample} {n_BCs} {fasta} {gff} {custom_name}
		# Before running, look at .eps files generated by sc_pipeline_15_generic.py ({sample}_bc1_ReadsPerBC.eps and {sample}_bc1_kneePlot.eps) in order to determine n_BCs (number of BCs to include in further analysis). It is best to initially comment out this line and only run it after looking at the .eps files generated by the first line of commands.sh.
		# n_BCs is typically 10000-40000
		# fasta is location and name of fasta for alignment
		# gff is location and name of gff for feature calling - see scripts/U00096_JE2_rRNA.gff for example format (specifically, gene names should be indicated by 'name=' and rRNA genes called 'rRNA'. Also, the feature type column should be uniform [e.g. every line is "Coding_or_RNA" in the example])
		# Custom name is a new name for the sample, corresponding to maybe the gff used or other specific input of the pipeline. For example, we might analyze the same cells by operon or by gene and would indicate that in the custom name. Custom name can be (and usually is) the same as sample name. 
		# pipeline_v2.sh includes a number of cleanup commands at the end. If interested in intermediate files, these can be easily commented out.

DEMO
We have provided a demo folder as an example of how to run the pipeline. We have included randomly selected ~20000 reads from 2 lanes of one of our PETRI-seq libraries. Execute the commands below to process 100 BCs from the demo library:

cd demo
./commands.sh ~/PETRI_seq_scripts_v2/scripts



A successful demo run will yield non-empty summary files random20000_v11_threshold_0_filtered_mapped_UMIs.txt and random20000_v11_threshold_0_mixed_species_gene_matrix.txt 
